{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMyJvJ8bzskx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "rng = np.random.default_rng()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_decoders = 8\n",
        "decoder_depth = 4\n",
        "decoder_channels = 32\n",
        "img_dim = 32\n",
        "img_channels = 3\n",
        "batch_size = 256\n",
        "PATH = 'model_checkpoint.pth'"
      ],
      "metadata": {
        "id": "RAw34T8rtqTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqjTI77tzsk8"
      },
      "outputs": [],
      "source": [
        "class normal_distribute_block(nn.Module):\n",
        "    def __init__(self, img_dim, sd):\n",
        "        super().__init__()\n",
        "        self.img_dim = img_dim\n",
        "        self.sd = sd\n",
        "        rng = np.random.default_rng()\n",
        "\n",
        "    def up_sd(self):\n",
        "      self.sd = self.sd + 0.05\n",
        "\n",
        "    def forward(self, x):\n",
        "        initial_deviations = self.sd * torch.randn((self.img_dim, self.img_dim)).to(device) + torch.ones((self.img_dim, self.img_dim)).to(device)\n",
        "        initial_mean = torch.zeros((self.img_dim, self.img_dim)).to(device)#, requires_grad=True)\n",
        "        initial_x = x\n",
        "        x = initial_deviations * x\n",
        "        x = x + initial_mean\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkXgJGlvzsk_"
      },
      "outputs": [],
      "source": [
        "class diffusion_forward(nn.Module):\n",
        "    def __init__(self, img_dim, num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.transformation = nn.ModuleList([\n",
        "            normal_distribute_block(img_dim, 0.1) for i in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.img_dim = img_dim\n",
        "        self.rm_rec = 0\n",
        "        self.rm_sq = 0\n",
        "\n",
        "    def inc_diff(self):\n",
        "      for block in self.transformation:\n",
        "        block.up_sd()\n",
        "\n",
        "    def up_removed_box(self):\n",
        "      self.rm_sq = self.rm_sq + 1\n",
        "      self.rm_rec = self.rm_rec + 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(0).repeat(self.num_layers+1, 1, 1, 1, 1)\n",
        "        for i, blur in enumerate(self.transformation):\n",
        "            x[i+1] = blur(x[i])\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSvdqIB5zslA"
      },
      "outputs": [],
      "source": [
        "class Unet(nn.Module):\n",
        "    def __init__(self, img_dim, num_layers, in_channels, initial_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.convolution_list = []\n",
        "        self.upscale_list = []\n",
        "        self.num_layers = num_layers\n",
        "        self.relu = nn.ReLU()\n",
        "        self.max_pool = nn.MaxPool2d(2, 2)\n",
        "        self.output_conv = nn.Conv2d(initial_channels, 3, 1)\n",
        "        self.convolution_list = nn.ModuleList([])\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            self.convolution_list.append(nn.ModuleList([nn.Conv2d(in_channels, initial_channels, 3, padding=1), nn.Conv2d(initial_channels, initial_channels, 3, padding=1), nn.Conv2d(initial_channels * 2, initial_channels, 3, padding=1)]))\n",
        "            in_channels = initial_channels\n",
        "            initial_channels = initial_channels * 2\n",
        "\n",
        "        self.intermediate_conv = nn.Conv2d(in_channels, initial_channels, 3, padding = 1)\n",
        "        self.middle_conv = nn.Conv2d(initial_channels, initial_channels, 3, padding = 1)\n",
        "\n",
        "    def upscale(self, x):\n",
        "        x = x.repeat_interleave(2, dim=2)\n",
        "        x = x.repeat_interleave(2, dim=3)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        xs_list = []\n",
        "        for layer in range(self.num_layers):\n",
        "            x = self.convolution_list[layer][0](x)\n",
        "            for i in range(1, 3):\n",
        "                x = self.relu(self.convolution_list[layer][1](x))\n",
        "            xs_list.append(x)\n",
        "            x = self.max_pool(x)\n",
        "\n",
        "        x = self.intermediate_conv(x)\n",
        "        x = self.middle_conv(x)\n",
        "\n",
        "        for layer in range(self.num_layers):\n",
        "            backward_layer = self.num_layers - layer - 1\n",
        "            x = self.upscale(x)\n",
        "            x = self.convolution_list[backward_layer][2](x)\n",
        "            x = x + xs_list[backward_layer]\n",
        "            for i in range(1, 3):\n",
        "                x = self.convolution_list[backward_layer][1](x)\n",
        "\n",
        "        x = self.output_conv(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class diffusion_backward(nn.Module):\n",
        "  def __init__(self, img_dim, num_layers, in_channels, initial_channels, num_decoders):\n",
        "      super().__init__()\n",
        "\n",
        "      self.num_decoders = num_decoders\n",
        "      self.unets = nn.ModuleList([\n",
        "          Unet(img_dim, num_layers, in_channels, initial_channels) for i in range(num_decoders)\n",
        "      ])\n",
        "\n",
        "  def disabe_unet(self, unet_no):\n",
        "      self.unets[unet_no] = self.unets[unet_no].detach()\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = x[num_decoders]\n",
        "      x_record = x.clone().unsqueeze(0).repeat(self.num_decoders+1, 1, 1, 1, 1)\n",
        "      for i in range(len(self.unets)):\n",
        "          x = self.unets[i](x.clone().detach())\n",
        "          x_record[num_decoders - i - 1] = x\n",
        "\n",
        "      return x_record"
      ],
      "metadata": {
        "id": "AqqZDfsHyAKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CuMNrYYzslC"
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "trainset = datasets.CIFAR10(root='.', train=True, download=True, transform=data_transform)\n",
        "testset = datasets.CIFAR10(root='.', train=False, download=True, transform=data_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "test_loader  = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j21POI3ZzslF"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "transform = T.ToPILImage()\n",
        "\n",
        "imshow(images.cpu().detach()[0])\n",
        "model_forward = diffusion_forward(img_dim, num_decoders).to(device)\n",
        "model_backward = diffusion_backward(img_dim, decoder_depth, img_channels, decoder_channels, num_decoders).cuda()\n",
        "\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "model2.train()\n",
        "\n",
        "images = images.to(device)\n",
        "for layer in range(num_decoders):\n",
        "  imshow(model1(images)[layer][0].cpu().detach())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = False\n",
        "\n",
        "if load_model:\n",
        "    model_backward.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "OQt089hFOHSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_backward.train()\n",
        "\n",
        "optimizers = []\n",
        "for i in range(len(model2.unets)):\n",
        "    optimizers.append(torch.optim.Adam(model2.unets[num_decoders - i - 1].parameters(), lr=1, eps=1))\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "schedulers = []\n",
        "for i in range(len(model2.unets)):\n",
        "    schedulers.append(lr_scheduler.StepLR(optimizers[i], step_size=10, gamma=0.5))\n",
        "\n",
        "model_forward.inc_diff()\n",
        "\n",
        "for i in range(1, 180):\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        images = data.to(device)\n",
        "        corrupted = model_forward(images)\n",
        "        restored = model_backward(corrupted)\n",
        "        total_loss = loss(restored, corrupted)\n",
        "        epoch_loss += total_loss.item()\n",
        "\n",
        "        for j in range(num_decoders):\n",
        "            optimizers[j].zero_grad()\n",
        "\n",
        "        total_loss.backward()\n",
        "        for j in range(num_decoders):\n",
        "            optimizers[j].step()\n",
        "\n",
        "    for j in range(num_decoders):\n",
        "        schedulers[j].step()\n",
        "\n",
        "    if i % 30 == 0:\n",
        "        model_forward.inc_diff()\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.param_groups[0]['lr'] = 1\n",
        "\n",
        "    if i % 1 == 0:\n",
        "      print(f'Epoch no: {i} , Loss: {epoch_loss / 60000}')"
      ],
      "metadata": {
        "id": "x0Azxg6QnzXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model2.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "vgF5VA36NXJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwQclp-vzslG"
      },
      "outputs": [],
      "source": [
        "model2.eval()\n",
        "image_num = 2\n",
        "\n",
        "imshow(images.cpu().detach()[image_num])\n",
        "max_blurred = model1(images)\n",
        "restored = model_backward(max_blurred)[:, image_num]\n",
        "imshow(max_blurred[8, image_num].cpu().detach())\n",
        "for i in range(num_decoders):\n",
        "  imshow(restored[i].cpu().detach())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}